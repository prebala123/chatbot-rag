{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Document CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Google Drive API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/documents.readonly']\n",
    "SERVICE_ACCOUNT_FILE = ''\n",
    "DOCUMENT_ID = ''\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "service = build('docs', 'v1', credentials=creds)\n",
    "document = service.documents().get(documentId=DOCUMENT_ID).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use regex patterns to extract question and answer data from the google doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_from_doc(doc):\n",
    "    content = doc.get('body').get('content')\n",
    "    faq_list = []\n",
    "    current_faq = {}\n",
    "    collecting_answer = False\n",
    "    collecting_question = False\n",
    "\n",
    "    question_patterns = [\n",
    "        re.compile(r'^(Question|Problem|Issue)\\s*:\\s*', re.IGNORECASE)\n",
    "    ]\n",
    "    answer_patterns = [\n",
    "        re.compile(r'^(Answer|Solution)\\s*:\\s*', re.IGNORECASE)\n",
    "    ]\n",
    "\n",
    "    def match_patterns(text, patterns):\n",
    "        for pattern in patterns:\n",
    "            if pattern.match(text):\n",
    "                return pattern\n",
    "        return None\n",
    "\n",
    "    # Loop through every FAQ block and extract relevant information\n",
    "    for element in content:\n",
    "        if 'paragraph' in element:\n",
    "            paragraph = element.get('paragraph')\n",
    "            text = ''.join([run.get('textRun', {}).get('content', '') for run in paragraph.get('elements')]).strip()\n",
    "            italic_found = any(run.get('textRun', {}).get('textStyle', {}).get('italic', False) for run in paragraph.get('elements'))\n",
    "\n",
    "            if text.startswith(\"FAQ #\"):\n",
    "                if 'question' in current_faq and 'answer' in current_faq:\n",
    "                    faq_list.append(current_faq)\n",
    "                current_faq = {\"faq_number\": text}\n",
    "                collecting_answer = False\n",
    "                collecting_question = False\n",
    "            elif text.startswith(\"Title:\"):\n",
    "                current_faq[\"title\"] = text.replace(\"Title:\", \"\").strip()\n",
    "            elif text.startswith(\"Tag:\"):\n",
    "                current_faq[\"tag\"] = text.replace(\"Tag:\", \"\").replace('â€™', '\\'').strip()\n",
    "            elif text.startswith(\"Author:\"):\n",
    "                current_faq[\"author\"] = text.replace(\"Author:\", \"\").strip()\n",
    "            elif match_patterns(text, question_patterns):\n",
    "                if 'question' in current_faq and 'answer' in current_faq:\n",
    "                    faq_list.append(current_faq)\n",
    "                    current_faq = {\"faq_number\": current_faq[\"faq_number\"]}\n",
    "                current_faq[\"question\"] = match_patterns(text, question_patterns).sub(\"\", text).strip()\n",
    "                collecting_answer = False\n",
    "                collecting_question = True\n",
    "            elif match_patterns(text, answer_patterns):\n",
    "                current_faq[\"answer\"] = [match_patterns(text, answer_patterns).sub(\"\", text).strip()]\n",
    "                collecting_answer = True\n",
    "                collecting_question = False\n",
    "            elif collecting_answer:\n",
    "                if italic_found:\n",
    "                    collecting_answer = False\n",
    "                else:\n",
    "                    if text:\n",
    "                        current_faq[\"answer\"].append(text)\n",
    "            elif collecting_question and text:\n",
    "                current_faq[\"question\"] += \" \" + text\n",
    "\n",
    "    # Add the last FAQ entry\n",
    "    if 'question' in current_faq and 'answer' in current_faq:\n",
    "        faq_list.append(current_faq)\n",
    "\n",
    "    # Convert answer lists to single strings\n",
    "    for faq in faq_list:\n",
    "        faq[\"answer\"] = '\\n'.join(faq[\"answer\"])\n",
    "\n",
    "    return faq_list\n",
    "\n",
    "qa_pairs = extract_qa_from_doc(document)\n",
    "df = pd.DataFrame(qa_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in csv file for more incident data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv('incidents.csv', skiprows=2)\n",
    "incidents = incidents.dropna(subset=['Incident Description', 'Opsmx Questions & Responses for the incidents'], axis=0)\n",
    "incidents = incidents[incidents['Incident Description'] != 'Incident Description'].reset_index(drop=True)\n",
    "incidents['title'] = incidents['Problem Statement']\n",
    "incidents['question'] = incidents['Incident Description']\n",
    "incidents['In Production'] = incidents['PROD']\n",
    "incidents['Support Team '] = incidents['Support Team '].fillna('None')\n",
    "incidents['answer'] = (\n",
    "    'Solution: ' + \n",
    "    incidents['Opsmx Questions & Responses for the incidents'] + \n",
    "    ' \\n\\nExtra Details: ' + \n",
    "    incidents['Support Team ']\n",
    ")\n",
    "incidents = incidents[['title', 'question', 'answer', 'Incident Date', 'In Production', 'Freshdesk ticket']]\n",
    "\n",
    "incidents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all DataFrames to get one csv file with all important data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.concat([df[['title', 'question', 'answer']], incidents[['title', 'question', 'answer']]]).reset_index(drop=True)\n",
    "questions.to_csv('questions-opsmx.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
