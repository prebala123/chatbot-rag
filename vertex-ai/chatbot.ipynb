{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "JmDQIAakKV71",
      "metadata": {
        "id": "JmDQIAakKV71"
      },
      "source": [
        "# Project Setup In Vertex AI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O8QnHZLhGX_v",
      "metadata": {
        "id": "O8QnHZLhGX_v"
      },
      "source": [
        "Install dependencies for vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7twl7n8sG2Jrwz8CgjHk1Bwu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 121011,
          "status": "ok",
          "timestamp": 1724093341204,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "7twl7n8sG2Jrwz8CgjHk1Bwu",
        "outputId": "65ef791c-f494-4504-9ba5-abf715e465ae",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-cloud-aiplatform langchain-core langchain-google-vertexai langchain-text-splitters langchain-community \"unstructured[all-docs]\" pypdf pydantic lxml pillow matplotlib opencv-python tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "we5Q205hGhjH",
      "metadata": {
        "id": "we5Q205hGhjH"
      },
      "source": [
        "Restart runtime to use installed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Sh3-auhkXZs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 173,
          "status": "ok",
          "timestamp": 1724093438139,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "1Sh3-auhkXZs",
        "outputId": "4293428a-3981-4082-8715-6085b21ad222"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eYsGnOIYGsHu",
      "metadata": {
        "id": "eYsGnOIYGsHu"
      },
      "source": [
        "Authenticate user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_GSuWlW8kjjv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1724093444939,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "_GSuWlW8kjjv",
        "outputId": "7c94493f-84cd-4a05-ba76-f35ca387026b"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_-2qfcM3G4qq",
      "metadata": {
        "id": "_-2qfcM3G4qq"
      },
      "source": [
        "Set up details about google cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeaUVPLkko0d",
      "metadata": {
        "id": "eeaUVPLkko0d"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# For Vector Search Staging\n",
        "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
        "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NczUN7o7G_Ev",
      "metadata": {
        "id": "NczUN7o7G_Ev"
      },
      "source": [
        "Start up vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "osFi2fSdku9N",
      "metadata": {
        "id": "osFi2fSdku9N"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=GCS_BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9H1m7b6RHB5C",
      "metadata": {
        "id": "9H1m7b6RHB5C"
      },
      "source": [
        "Import libraries used for the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tOq_SW5GkvXz",
      "metadata": {
        "id": "tOq_SW5GkvXz"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import uuid\n",
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "import ast\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "from langchain_google_vertexai import (\n",
        "    VertexAI,\n",
        "    ChatVertexAI,\n",
        "    VertexAIEmbeddings,\n",
        "    VectorSearchVectorStore,\n",
        ")\n",
        "\n",
        "from unstructured.partition.pdf import partition_pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MxpIjN9QHHUl",
      "metadata": {
        "id": "MxpIjN9QHHUl"
      },
      "source": [
        "Set up model information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aDWWwY3vkyhh",
      "metadata": {
        "id": "aDWWwY3vkyhh"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gemini-1.0-pro\"\n",
        "GEMINI_OUTPUT_TOKEN_LIMIT = 8192\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-004\"\n",
        "EMBEDDING_TOKEN_LIMIT = 2048\n",
        "\n",
        "TOKEN_LIMIT = min(GEMINI_OUTPUT_TOKEN_LIMIT, EMBEDDING_TOKEN_LIMIT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YdEwoO-XKdnJ",
      "metadata": {
        "id": "YdEwoO-XKdnJ"
      },
      "source": [
        "# Document Storage Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YEW16LLCKkCp",
      "metadata": {
        "id": "YEW16LLCKkCp"
      },
      "source": [
        "These cells have to be run to set up the vectorstore.\n",
        "\n",
        "First bring data to local directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FdL8wKdDk6nE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 3807,
          "status": "ok",
          "timestamp": 1725037603240,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "FdL8wKdDk6nE",
        "outputId": "9e422fbf-e858-455f-a8ed-12504a07c216"
      },
      "outputs": [],
      "source": [
        "!gsutil -m rsync -r <path> ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GzZTDtkVLCEj",
      "metadata": {
        "id": "GzZTDtkVLCEj"
      },
      "source": [
        "Read in data file and convert to list of documents to add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZSRXFCPjlaKO",
      "metadata": {
        "executionInfo": {
          "elapsed": 190,
          "status": "ok",
          "timestamp": 1725037949130,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "ZSRXFCPjlaKO"
      },
      "outputs": [],
      "source": [
        "documents = pd.read_csv('documents.csv')\n",
        "doc_ids = list(documents['id'])\n",
        "documents = documents[['title', 'question', 'answer']]\n",
        "documents = json.loads(documents.T.to_json())\n",
        "texts = []\n",
        "for doc in documents:\n",
        "  texts.append(str(documents[doc]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nhgUAI_eMJQv",
      "metadata": {
        "id": "nhgUAI_eMJQv"
      },
      "source": [
        "Create index to store all of the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vlo695JYLZbR",
      "metadata": {
        "id": "vlo695JYLZbR"
      },
      "outputs": [],
      "source": [
        "DIMENSIONS = 768\n",
        "\n",
        "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=\"llm_documents_index\",\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        "    description=\"Document Storage for LLM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4EJrIksNMNlP",
      "metadata": {
        "id": "4EJrIksNMNlP"
      },
      "source": [
        "Create endpoint to access documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-WJuoAUPL7Fh",
      "metadata": {
        "id": "-WJuoAUPL7Fh"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_INDEX_ID = \"llm_documents_endpoint\"\n",
        "\n",
        "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=DEPLOYED_INDEX_ID,\n",
        "    description=\"Index Endpoint for LLM\",\n",
        "    public_endpoint_enabled=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZWUhOGciMa7Y",
      "metadata": {
        "id": "ZWUhOGciMa7Y"
      },
      "source": [
        "Deploy index to endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uif5Gy4cMbvk",
      "metadata": {
        "id": "uif5Gy4cMbvk"
      },
      "outputs": [],
      "source": [
        "index_endpoint = index_endpoint.deploy_index(\n",
        "    index=index, deployed_index_id=\"llm_documents_index\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jvwyT5BkM5Lt",
      "metadata": {
        "id": "jvwyT5BkM5Lt"
      },
      "source": [
        "Create vectorstore to save embedding vectors of the documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WlJkUqtXlj-z",
      "metadata": {
        "id": "WlJkUqtXlj-z"
      },
      "outputs": [],
      "source": [
        "vectorstore = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=LOCATION,\n",
        "    gcs_bucket_name=GCS_BUCKET,\n",
        "    index_id=index.name,\n",
        "    endpoint_id=index_endpoint.name,\n",
        "    embedding=VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
        "    stream_update=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jTAPzpYXZfaC",
      "metadata": {
        "id": "jTAPzpYXZfaC"
      },
      "source": [
        "Create retriever to get documents by embeddings and docstore to map documents to embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YWo3ihPGZeFW",
      "metadata": {
        "id": "YWo3ihPGZeFW"
      },
      "outputs": [],
      "source": [
        "docstore = InMemoryStore()\n",
        "\n",
        "id_key = \"doc_id\"\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=docstore,\n",
        "    id_key=id_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RnLLMznbpw8k",
      "metadata": {
        "id": "RnLLMznbpw8k"
      },
      "source": [
        "Store the document ids for retrieval later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stMpdM0nePq3",
      "metadata": {
        "id": "stMpdM0nePq3"
      },
      "outputs": [],
      "source": [
        "all_docs = [\n",
        "    Document(page_content=str(s), metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(texts)\n",
        "]\n",
        "retriever.docstore.mset(list(zip(doc_ids, texts)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wH4ADa3Ip2Yx",
      "metadata": {
        "id": "wH4ADa3Ip2Yx"
      },
      "source": [
        "Add document embeddings to the vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t70DZPveeoMT",
      "metadata": {
        "collapsed": true,
        "id": "t70DZPveeoMT"
      },
      "outputs": [],
      "source": [
        "retriever.vectorstore.add_documents(all_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8sxPfIBAqLmg",
      "metadata": {
        "id": "8sxPfIBAqLmg"
      },
      "source": [
        "# Create LLM with RAG from vectorstore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RpkQexINrLEv",
      "metadata": {
        "id": "RpkQexINrLEv"
      },
      "source": [
        "Get index id and endpoint id to create vectorstore object from here the vertex ai cloud console in the vector search tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lMLQHMQ0q72P",
      "metadata": {
        "id": "lMLQHMQ0q72P"
      },
      "outputs": [],
      "source": [
        "index_id = ''\n",
        "endpoint_id = ''\n",
        "\n",
        "vectorstore = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=LOCATION,\n",
        "    gcs_bucket_name=GCS_BUCKET,\n",
        "    index_id=index_id,\n",
        "    endpoint_id=endpoint_id,\n",
        "    embedding=VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
        "    stream_update=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nOjs9qlQ0AnH",
      "metadata": {
        "id": "nOjs9qlQ0AnH"
      },
      "source": [
        "Create retriever to get documents from vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m2pdJL1Wrhie",
      "metadata": {
        "id": "m2pdJL1Wrhie"
      },
      "outputs": [],
      "source": [
        "docstore = InMemoryStore()\n",
        "\n",
        "id_key = \"doc_id\"\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=docstore,\n",
        "    id_key=id_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SAtTAJc20EJz",
      "metadata": {
        "id": "SAtTAJc20EJz"
      },
      "source": [
        "Add dictionary to convert embeddings back to original documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I_0r9sZgrza-",
      "metadata": {
        "id": "I_0r9sZgrza-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('documents.csv')\n",
        "doc_ids = list(df['id'])\n",
        "df = df[['title', 'question', 'answer']]\n",
        "text = df.T.to_json()\n",
        "text = json.loads(text)\n",
        "texts = []\n",
        "for k in text:\n",
        "  texts.append(str(text[k]))\n",
        "retriever.docstore.mset(list(zip(doc_ids, texts)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R5-7-yH30QKZ",
      "metadata": {
        "id": "R5-7-yH30QKZ"
      },
      "source": [
        "Create chain pipeline to retrieve documents then generate answer to the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9DONKXysmO4n",
      "metadata": {
        "id": "9DONKXysmO4n"
      },
      "outputs": [],
      "source": [
        "def combine_context_question(inputs):\n",
        "    \"\"\"\n",
        "    Combine the context and question to create the prompt for the LLM\n",
        "    \"\"\"\n",
        "    context = inputs.get(\"context\", \"\")\n",
        "    question = inputs.get(\"question\", \"\")\n",
        "    prompt = f\"Context: {context}\\n\\nQuestion: {question}\"\n",
        "    return prompt\n",
        "\n",
        "llm_chain = (\n",
        "    {\n",
        "        \"context\": retriever, # Retrieve similar documents\n",
        "        \"question\": RunnablePassthrough(), # Question from user\n",
        "    }\n",
        "    | RunnableLambda(combine_context_question) # Create a combined prompt\n",
        "    | ChatVertexAI( # Ask question to LLM\n",
        "        temperature=0,\n",
        "        model_name=MODEL_NAME,\n",
        "        max_output_tokens=TOKEN_LIMIT,\n",
        "    )\n",
        "    | StrOutputParser() # Return output\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G0lPW7io1d-7",
      "metadata": {
        "id": "G0lPW7io1d-7"
      },
      "source": [
        "Run llm chain to get answer to question from retrieved documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jPYFCxYglw6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 6837,
          "status": "ok",
          "timestamp": 1724096037458,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "jPYFCxYglw6e",
        "outputId": "92ff03d2-b311-4180-c858-ca520f91892c"
      },
      "outputs": [],
      "source": [
        "query = \"\"\n",
        "\n",
        "result = llm_chain.invoke(query)\n",
        "\n",
        "Markdown(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chatbot",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
